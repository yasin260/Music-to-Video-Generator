{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸµ Music-to-Video Generation using AI  \n"
      ],
      "metadata": {
        "id": "wOVwPVODeN_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ¬ Ø¹Ù†ÙˆØ§Ù† Ù¾Ø±ÙˆÚ˜Ù‡: Music-to-Video Generator  \n",
        "\n",
        "\n",
        "### ğŸ« Ø¯Ø±Ø³  \n",
        "**Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù†Ù‡ÙØªÙ‡ Ùˆ Ø¨ÛŒâ€ŒØ¯Ø±Ù†Ú¯**\n",
        "\n",
        "### ğŸ‘¨â€ğŸ« Ø§Ø³ØªØ§Ø¯  \n",
        "**Ù…Ù‡Ù†Ø¯Ø³ Ù…Ù‡Ø¯ÛŒ Ø³ÛŒÙÛŒâ€ŒÙ¾ÙˆØ±**\n",
        "\n",
        "### ğŸ‘¥ Ø§Ø¹Ø¶Ø§ÛŒ ØªÛŒÙ…  \n",
        "- Ø³ÛŒØ¯ Ù…Ù‡Ø¯ÛŒ Ù…Ù†Ø¬Ù…  \n",
        "- Ø¹Ù„ÛŒØ±Ø¶Ø§ Ù…ÛŒØ±Ø²Ø§ÛŒÛŒ  \n",
        "- Ù…Ø­Ù…Ø¯Ø­Ø³ÛŒÙ† ÙØ±Ù‡Ø§Ø¯ÛŒØ§Ù†  \n",
        "\n",
        "### ğŸ“… ØªØ§Ø±ÛŒØ®  \n",
        "ØªØ§Ø¨Ø³ØªØ§Ù† 1404  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "EONLFgqleXHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ¨ Ú†Ú©ÛŒØ¯Ù‡  \n",
        "\n",
        "Ø¯Ø± Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ØŒ Ø³Ø§Ù…Ø§Ù†Ù‡â€ŒØ§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø·Ø±Ø§Ø­ÛŒ Ùˆ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª Ú©Ù‡ Ù‚Ø§Ø¨Ù„ÛŒØª **ØªØ¨Ø¯ÛŒÙ„ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø¨Ù‡ ÙˆÛŒØ¯Ø¦Ùˆ** Ø±Ø§ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯.  \n",
        "ÙØ±Ø¢ÛŒÙ†Ø¯ Ú©Ù„ÛŒ Ø´Ø§Ù…Ù„ Ú†Ù‡Ø§Ø± Ù…Ø±Ø­Ù„Ù‡â€ŒÛŒ Ø§ØµÙ„ÛŒ Ø§Ø³Øª:  \n",
        "1. **Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙˆØª** Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† (Ø§Ø´Ø¹Ø§Ø±) **Whisper**  \n",
        "2. **ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡** Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡ ØªÙˆØ³Ø· Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù†ÛŒ **Gemini**  \n",
        "3. **ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø§ÙˆÙ„ÛŒÙ‡** **Stable Diffusion XL**  \n",
        "4. **ØªØ¨Ø¯ÛŒÙ„ ØªØµÙˆÛŒØ± Ø¨Ù‡ ÙˆÛŒØ¯Ø¦Ùˆ** **Stable Video Diffusion**  \n",
        "\n",
        "Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø³Ø§Ù…Ø§Ù†Ù‡ØŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ Ø§Ø³Øª Ú©Ù‡ Ø¨Ø§ Ù…Ø­ØªÙˆØ§ÛŒ Ù…ÙˆØ³ÛŒÙ‚ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ù‡Ù…Ø§Ù‡Ù†Ú¯ Ø¨ÙˆØ¯Ù‡ Ùˆ Ø¬Ù†Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡Ù†Ø±ÛŒØŒ Ø§Ø­Ø³Ø§Ø³ÛŒ Ùˆ Ø¨ØµØ±ÛŒ Ø¢Ù† Ø±Ø§ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡ Ø¨Ø§Ø²Ø¢ÙØ±ÛŒÙ†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.  \n",
        "\n",
        "Ø§ÛŒÙ† Ø³ÛŒØ³ØªÙ… Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² **Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ù…ÛŒØ§Ù†â€ŒØ±Ø´ØªÙ‡â€ŒØ§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ** Ø¯Ø± ØªØ±Ú©ÛŒØ¨ Ø­ÙˆØ²Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒØŒ Ø¨ÛŒÙ†Ø§ÛŒÛŒ Ù…Ø§Ø´ÛŒÙ† Ùˆ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ú†Ù†Ø¯Ø±Ø³Ø§Ù†Ù‡â€ŒØ§ÛŒ Ø¨Ù‡ Ø´Ù…Ø§Ø± Ù…ÛŒâ€ŒØ±ÙˆØ¯.  \n"
      ],
      "metadata": {
        "id": "S4rEVvJrez_Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LWlNJ5f3Ikg",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install pydub whisper-openai google-generativeai python-dotenv diffusers transformers accelerate torch torchvision imageio[ffmpeg]\n",
        "!pip install --upgrade Pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "XwNWDIFH4Zv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“Œ Ú¯Ø§Ù… ÛŒÚ©: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ†  \n",
        "Ø¯Ø± Ù†Ø®Ø³ØªÛŒÙ† Ú¯Ø§Ù…ØŒ ÙØ§ÛŒÙ„ Ù…ÙˆØ³ÛŒÙ‚ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ø¯Ø± Ù‚Ø§Ù„Ø¨ **Ø§Ù… Ù¾ÛŒ ØªØ±ÛŒ** Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ Ø¨Ù‡ ÙØ±Ù…Øª **ÙˆÛŒÙˆ** ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯.  \n",
        "Ø³Ù¾Ø³ Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø¨Ù‡ Ù…Ø¯Ù„ **ÙˆÛŒØ³Ù¾Ø±** Ø¯Ø§Ø¯Ù‡ Ø´Ø¯ ØªØ§ Ù…Ø­ØªÙˆØ§ÛŒ ØµÙˆØªÛŒ Ø¢Ù† ØªØ­Ù„ÛŒÙ„ Ø´Ø¯Ù‡ Ùˆ Ù…ØªÙ† (Ø§Ø´Ø¹Ø§Ø±) Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú¯Ø±Ø¯Ø¯.  \n",
        "Ø¯Ø± Ù†Ù‡Ø§ÛŒØª Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² **Ø¬Ù…ÛŒÙ†ÛŒ** Ù¾Ø±Ø§Ù…Ù¾Øª Ù…ØªÙ†Ø§Ø³Ø¨ Ø¨Ø§ Ù…ÙˆØ³ÛŒÙ‚ÛŒ ØªÙˆÙ„ÛŒØ¯ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
        "\n",
        "Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡ØŒ Ù¾Ø§ÛŒÙ‡ Ùˆ Ø§Ø³Ø§Ø³ Ø³Ø§ÛŒØ± Ù…Ø±Ø§Ø­Ù„ Ù¾Ø±ÙˆÚ˜Ù‡ Ù…Ø­Ø³ÙˆØ¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯Ø› Ø²ÛŒØ±Ø§ Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡ Ù…Ø¨Ù†Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡ Ùˆ Ø¯Ø± Ù†Ù‡Ø§ÛŒØª ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ùˆ ÙˆÛŒØ¯Ø¦Ùˆ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯.  \n"
      ],
      "metadata": {
        "id": "c-kDRjkThF-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper\n",
        "import google.generativeai as genai\n",
        "from pydub import AudioSegment\n",
        "from google.colab import userdata\n",
        "\n",
        "# ---------------- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ ----------------\n",
        "AUDIO_INPUT_PATH = \"song.mp3\"\n",
        "WAV_OUTPUT_PATH = \"input.wav\"\n",
        "LYRICS_PATH = \"lyrics.txt\"\n",
        "PROMPT_PATH = \"video_prompt.txt\"\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "# ---------------- ØªØ¨Ø¯ÛŒÙ„ mp3 Ø¨Ù‡ wav ----------------\n",
        "def convert_mp3_to_wav(input_path, output_path):\n",
        "    print(\"Converting from MP3 to WAV...\")\n",
        "    try:\n",
        "        sound = AudioSegment.from_file(input_path)\n",
        "        sound.export(output_path, format=\"wav\")\n",
        "        print(\"Conversion completed.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error during MP3 to WAV conversion: {e}\")\n",
        "        return False\n",
        "\n",
        "# ---------------- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø¨Ø§ Whisper ----------------\n",
        "def extract_lyrics(wav_path):\n",
        "    print(\"Extracting text with Whisper...\")\n",
        "    try:\n",
        "        model = whisper.load_model(\"base\")\n",
        "        result = model.transcribe(wav_path)\n",
        "        text = result[\"text\"]\n",
        "        print(\"Text extracted.\")\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error during text extraction with Whisper: {e}\")\n",
        "        return None\n",
        "\n",
        "# ---------------- ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª Ø¨Ø§ Gemini ----------------\n",
        "def generate_prompt_from_lyrics(lyrics, api_key):\n",
        "    print(\"Producing prompts with Gemini...\")\n",
        "    if not api_key:\n",
        "        print(\"GEMINI_API_KEY is not set.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        genai.configure(api_key=api_key)\n",
        "        model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
        "\n",
        "        system_prompt = f\"\"\"\n",
        "You are a creative assistant. Based on the lyrics of the song below, create a cinematic script for a text-to-video model. The script should clearly describe the mood, visual style, colors, environment, and emotions.\n",
        "\n",
        "Lyrics:\n",
        "\n",
        "{lyrics}\n",
        "\n",
        "Write it creatively and concisely, suitable for AI video production tools like Stable Video or ModelScope, in a few lines and short.\n",
        "\n",
        "\"\"\"\n",
        "        response = model.generate_content(system_prompt)\n",
        "        print(\"Prompt generated.\")\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error during prompt generation with Gemini: {e}\")\n",
        "        return None\n",
        "\n",
        "# ---------------- Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ ----------------\n",
        "def main():\n",
        "    if not os.path.exists(AUDIO_INPUT_PATH):\n",
        "        print(f\"Audio file '{AUDIO_INPUT_PATH}' not found.\")\n",
        "        return\n",
        "\n",
        "    # Ù…Ø±Ø­Ù„Ù‡ 1: ØªØ¨Ø¯ÛŒÙ„ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ\n",
        "    if not convert_mp3_to_wav(AUDIO_INPUT_PATH, WAV_OUTPUT_PATH):\n",
        "        return\n",
        "\n",
        "    # Ù…Ø±Ø­Ù„Ù‡ 2: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ†\n",
        "    lyrics = extract_lyrics(WAV_OUTPUT_PATH)\n",
        "    if not lyrics:\n",
        "        return\n",
        "\n",
        "    with open(LYRICS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(lyrics)\n",
        "\n",
        "    # Ù…Ø±Ø­Ù„Ù‡ 3: ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª\n",
        "    prompt = generate_prompt_from_lyrics(lyrics, GEMINI_API_KEY)\n",
        "    if not prompt:\n",
        "        print(\"\\nCould not generate prompt. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Ù…Ø±Ø­Ù„Ù‡ 4: Ø°Ø®ÛŒØ±Ù‡ Ù¾Ø±Ø§Ù…Ù¾Øª\n",
        "    with open(PROMPT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(prompt)\n",
        "\n",
        "    print(f\"\\n--- Prompt generated by Gemini ---\\n{prompt}\\n----------------------------------\")\n",
        "    print(\"\\nEverything is ready. Lyrics and prompt saved.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "0PIfShu15Ahy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“Œ Ú¯Ø§Ù… Ø¯ÙˆÙ…: ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø§ÙˆÙ„ÛŒÙ‡\n",
        "\n",
        "Ø¯Ø± Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡ØŒ Ù…ØªÙ†ÛŒ Ú©Ù‡ ØªÙˆØ³Ø· Ù…Ø¯Ù„ Ø¬ÙÙ…ÛŒÙ†ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø´Ø¹Ø§Ø± Ù…ÙˆØ³ÛŒÙ‚ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø¨ÙˆØ¯ØŒ\n",
        "Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù¾Ø±Ø§Ù…Ù¾Øª ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ù‡ Ù…Ø¯Ù„ Ø§Ø³ØªÛŒØ¨Ù„ Ø¯ÛŒÙÛŒÙˆØ´Ù† Ø§ÛŒÚ©Ø³â€ŒØ§Ù„ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯.\n",
        "Ø§ÛŒÙ† Ù…Ø¯Ù„ ÙˆØ¸ÛŒÙÙ‡ Ø¯Ø§Ø´Øª ØªØ§ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªÙˆØµÛŒÙØ§Øª Ù…ØªÙ†ÛŒØŒ ÛŒÚ© ØªØµÙˆÛŒØ± Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†Ø¯.\n",
        "\n",
        "ØªØµÙˆÛŒØ± Ø¨Ù‡ Ø¯Ø³Øª Ø¢Ù…Ø¯Ù‡ Ø¯Ø± Ø§ÛŒÙ† ÙØ±Ø¢ÛŒÙ†Ø¯ØŒ Ù†Ù‚Ø·Ù‡ Ø´Ø±ÙˆØ¹ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ÙˆÛŒØ¯Ø¦Ùˆ Ù…Ø­Ø³ÙˆØ¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
        "Ø¯Ø± Ø§ÛŒÙ† Ú¯Ø§Ù… Ù‡Ù…Ú†Ù†ÛŒÙ† ØªÙ†Ø¸ÛŒÙ…Ø§ØªÛŒ Ù…Ø§Ù†Ù†Ø¯ Ø§Ù†Ø¯Ø§Ø²Ù‡ ØªØµÙˆÛŒØ± Ùˆ Ú©Ù†ØªØ±Ù„ Ø¨Ø°Ø± ØªØµØ§Ø¯ÙÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯\n",
        "ØªØ§ ØªÚ©Ø±Ø§Ø±Ù¾Ø°ÛŒØ±ÛŒ Ùˆ ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ Ø¯Ø± Ù†ØªØ§ÛŒØ¬ ØªØ¶Ù…ÛŒÙ† Ú¯Ø±Ø¯Ø¯.\n",
        "\n",
        "Ø¯Ø± Ù†ØªÛŒØ¬Ù‡ØŒ Ø®Ø±ÙˆØ¬ÛŒ Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡ ÛŒÚ© ØªØµÙˆÛŒØ± Ø§Ø³Øª Ú©Ù‡ Ø§Ø±ØªØ¨Ø§Ø· Ù…Ø³ØªÙ‚ÛŒÙ…ÛŒ Ø¨Ø§ ÙØ¶Ø§ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ\n",
        "Ø§Ø´Ø¹Ø§Ø± Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø¯Ø§Ø±Ø¯ Ùˆ Ù…Ø¨Ù†Ø§ÛŒ Ú¯Ø§Ù… Ø³ÙˆÙ… ÛŒØ¹Ù†ÛŒ ØªÙˆÙ„ÛŒØ¯ ÙˆÛŒØ¯Ø¦Ùˆ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯."
      ],
      "metadata": {
        "id": "WgaMTHe2iCZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "!pip install diffusers transformers accelerate torch torchvision imageio[ffmpeg]\n",
        "!pip install --upgrade Pillow"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IbCroPJ99R9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from diffusers import DiffusionPipeline\n",
        "from PIL import Image\n",
        "\n",
        "# ---------------- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ ----------------\n",
        "PROMPT_PATH = \"video_prompt.txt\"\n",
        "INITIAL_IMAGE_PATH = \"initial_image.png\"\n",
        "\n",
        "# ---------------- ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ Stable Diffusion XL ----------------\n",
        "def generate_initial_image(prompt, output_path):\n",
        "    print(\"Generating initial image with Stable Diffusion XL...\")\n",
        "    try:\n",
        "        # Load the text-to-image model (SDXL)\n",
        "        txt2img_pipe = DiffusionPipeline.from_pretrained(\n",
        "            \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "            torch_dtype=torch.float16,\n",
        "            variant=\"fp16\"\n",
        "        )\n",
        "        txt2img_pipe.to(\"cuda\")\n",
        "\n",
        "        # Generate the initial image from the prompt\n",
        "        generator = torch.manual_seed(42)\n",
        "        initial_image = txt2img_pipe(prompt=prompt, generator=generator).images[0]\n",
        "        initial_image.save(output_path)\n",
        "        print(\"Initial image generated and saved.\")\n",
        "\n",
        "        # Clear GPU memory\n",
        "        del txt2img_pipe\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error during image generation: {e}\")\n",
        "        return False\n",
        "\n",
        "# ---------------- Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø§ÙˆÙ„ÛŒÙ‡ ----------------\n",
        "def main_image_generation():\n",
        "    if not os.path.exists(PROMPT_PATH):\n",
        "        print(f\"Prompt file '{PROMPT_PATH}' not found. Please run the first cell to generate the prompt.\")\n",
        "        return\n",
        "\n",
        "    with open(PROMPT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        prompt = f.read()\n",
        "\n",
        "    print(f\"\\n--- Using saved prompt to generate initial image ---\\n{prompt}\\n----------------------------------\")\n",
        "\n",
        "    if generate_initial_image(prompt, INITIAL_IMAGE_PATH):\n",
        "        print(\"\\nInitial image generation completed successfully.\")\n",
        "    else:\n",
        "        print(\"\\nInitial image generation failed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_image_generation()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qjmNJycM_xeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ğŸ“Œ Ú¯Ø§Ù… Ø³ÙˆÙ…: ØªÙˆÙ„ÛŒØ¯ ÙˆÛŒØ¯Ø¦Ùˆ\n",
        "\n",
        "Ø¯Ø± Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡ØŒ ØªØµÙˆÛŒØ± Ø§ÙˆÙ„ÛŒÙ‡ ØªÙˆÙ„ÛŒØ¯Ø´Ø¯Ù‡ ØªÙˆØ³Ø· Ù…Ø¯Ù„ Ø§Ø³ØªÛŒØ¨Ù„ Ø¯ÛŒÙÛŒÙˆØ´Ù† Ø§ÛŒÚ©Ø³â€ŒØ§Ù„ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ù‡ Ù…Ø¯Ù„ Ø§Ø³ØªÛŒØ¨Ù„ ÙˆÛŒØ¯Ø¦Ùˆ Ø¯ÛŒÙÛŒÙˆØ´Ù† Ø¯Ø§Ø¯Ù‡ Ø´Ø¯ ØªØ§ ÛŒÚ© ÙˆÛŒØ¯Ø¦Ùˆ Ú©ÙˆØªØ§Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø±Ø¯Ø¯.\n",
        "Ø§ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªÙˆØµÛŒÙØ§Øª Ù¾Ø±Ø§Ù…Ù¾Øª Ùˆ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØµÙˆÛŒØ± Ø§ÙˆÙ„ÛŒÙ‡ØŒ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù…ØªÙˆØ§Ù„ÛŒ Ùˆ Ø­Ø±Ú©Øªâ€ŒÙ‡Ø§ÛŒ Ø·Ø¨ÛŒØ¹ÛŒ Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.\n",
        "\n",
        "ØªÙ†Ø¸ÛŒÙ…Ø§ØªÛŒ Ù…Ø§Ù†Ù†Ø¯ ØªØ¹Ø¯Ø§Ø¯ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ØŒ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ùˆ Ø±Ø²ÙˆÙ„ÙˆØ´Ù† ØªØµÙˆÛŒØ±ØŒ Ùˆ Ø´Ø¯Øª Ù†ÙˆÛŒØ² Ø­Ø±Ú©ØªÛŒ Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯ ØªØ§ ÙˆÛŒØ¯Ø¦Ùˆ Ù†Ù‡Ø§ÛŒÛŒ Ø§Ø² Ù†Ø¸Ø± Ø¨ØµØ±ÛŒ Ù‡Ù…Ø§Ù‡Ù†Ú¯ Ùˆ Ø±ÙˆØ§Ù† Ø¨Ø§Ø´Ø¯.\n",
        "Ø®Ø±ÙˆØ¬ÛŒ Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡ØŒ ÛŒÚ© ÙˆÛŒØ¯Ø¦Ùˆ Ù‡Ù†Ø±ÛŒ Ùˆ Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡ Ø§Ø³Øª Ú©Ù‡ Ø¨ÛŒØ§Ù†Ú¯Ø± ÙØ¶Ø§ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ùˆ Ø§Ø­Ø³Ø§Ø³ÛŒ Ø§Ø´Ø¹Ø§Ø± Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ø¨ÙˆØ¯Ù‡ Ùˆ Ù†ØªÛŒØ¬Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ Ø±Ø§ ØªØ´Ú©ÛŒÙ„ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.\n",
        "\n",
        "âŒ**Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ù…ÛŒØ²Ø§Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· Ú¯ÙˆÚ¯Ù„ Ú©Ù„Ø¨ Ø¨ÙˆØ¯Ù‡ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ÙˆÛŒØ¯Ø¦Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø®Ø±ÙˆØ¬ÛŒ Ø±ÙˆÛŒ Ú©ÛŒÙÛŒØª Ù¾Ø§ÛŒÛŒÙ† ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡ Ø§Ø³ØªâŒ**"
      ],
      "metadata": {
        "id": "EI3MsjhFjX3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from diffusers import StableVideoDiffusionPipeline\n",
        "from diffusers.utils import load_image, export_to_video\n",
        "from PIL import Image\n",
        "import imageio\n",
        "\n",
        "# ---------------- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ ----------------\n",
        "INITIAL_IMAGE_PATH = \"initial_image.png\"\n",
        "VIDEO_OUTPUT_PATH = \"generated_video.mp4\"\n",
        "\n",
        "# ---------------- ØªÙˆÙ„ÛŒØ¯ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ø§ Stable Video Diffusion ----------------\n",
        "def generate_video_from_image(image_path, output_path):\n",
        "    print(\"Generating video from the initial image with Stable Video Diffusion...\")\n",
        "    try:\n",
        "        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø³Ø§Ø®Øª ÙˆÛŒØ¯ÛŒÙˆ\n",
        "        pipe = StableVideoDiffusionPipeline.from_pretrained(\n",
        "            \"stabilityai/stable-video-diffusion-img2vid-xt\",\n",
        "            torch_dtype=torch.float16,\n",
        "            variant=\"fp16\"\n",
        "        )\n",
        "        pipe.to(\"cuda\")\n",
        "\n",
        "        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ± Ø§ÙˆÙ„ÛŒÙ‡\n",
        "        initial_image = load_image(image_path)\n",
        "\n",
        "        # --- ØªØºÛŒÛŒØ± Ø§ÙˆÙ„: Ú©Ø§Ù‡Ø´ Ø§Ø¨Ø¹Ø§Ø¯ ØªØµÙˆÛŒØ± ---\n",
        "        # Ù…Ø§ Ø±Ø²ÙˆÙ„ÙˆØ´Ù† Ø±Ùˆ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ú©Ù…ØªØ± Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "        target_size = 512\n",
        "        width, height = initial_image.size\n",
        "        if height > width:\n",
        "            new_height = target_size\n",
        "            new_width = int(new_height * width / height)\n",
        "        else:\n",
        "            new_width = target_size\n",
        "            new_height = int(new_width * height / width)\n",
        "\n",
        "        new_width = new_width - new_width % 8\n",
        "        new_height = new_height - new_height % 8\n",
        "\n",
        "        initial_image = initial_image.resize((new_width, new_height))\n",
        "        print(f\"Image resized to: {initial_image.size}\")\n",
        "\n",
        "\n",
        "        # ØªÙˆÙ„ÛŒØ¯ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆ\n",
        "        # --- ØªØºÛŒÛŒØ± Ø¯ÙˆÙ…: Ú©Ø§Ù‡Ø´ decode_chunk_size ---\n",
        "        video_frames = pipe(\n",
        "            initial_image,\n",
        "            num_frames=25,\n",
        "            decode_chunk_size=4, # Ø§ÛŒÙ† Ø¹Ø¯Ø¯ Ø§Ø² 8 Ø¨Ù‡ 4 Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØª\n",
        "            motion_bucket_id=127,\n",
        "            noise_aug_strength=0.1\n",
        "        ).frames[0]\n",
        "\n",
        "        print(\"Video frames generated. Saving the video...\")\n",
        "\n",
        "        # Ø°Ø®ÛŒØ±Ù‡ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª ÙØ§ÛŒÙ„ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ mp4\n",
        "        export_to_video(video_frames, output_path, fps=7)\n",
        "\n",
        "        # Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡ GPU\n",
        "        del pipe\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        print(f\"Video saved successfully at: {output_path}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during video generation: {e}\")\n",
        "        return False\n",
        "\n",
        "# ---------------- Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ÙˆÛŒØ¯ÛŒÙˆ ----------------\n",
        "def main_video_generation():\n",
        "    if not os.path.exists(INITIAL_IMAGE_PATH):\n",
        "        print(f\"Initial image '{INITIAL_IMAGE_PATH}' not found. Please run the previous cells first.\")\n",
        "        return\n",
        "\n",
        "    if generate_video_from_image(INITIAL_IMAGE_PATH, VIDEO_OUTPUT_PATH):\n",
        "        print(\"\\nVideo generation completed successfully.\")\n",
        "    else:\n",
        "        print(\"\\nVideo generation failed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_video_generation()"
      ],
      "metadata": {
        "id": "aRezV5E_BJhM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}